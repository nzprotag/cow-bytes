{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from triplet_utils import *\n",
    "from utils import *\n",
    "from torch.utils.data import random_split\n",
    "from triplet_utils import train_and_evaluate_triplet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TripletModel definition\n",
    "class TripletModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletModel, self).__init__()\n",
    "        self.base_model = models.resnet50(pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(self.base_model.fc.in_features, 128)  # Adjust output size for embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding directly from the base model\n",
    "        return self.base_model(x)  # Call the model with input x\n",
    "\n",
    "class TripletClassifier(nn.Module):\n",
    "    def __init__(self, triplet_head, output_size=1):\n",
    "        super(TripletClassifier, self).__init__()\n",
    "        self.triplet_head = triplet_head\n",
    "        self.classifier = nn.Linear(self.triplet_head.base_model.fc.out_features, output_size)  # Binary classification (logits)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedding = self.triplet_head(x)  # Output of base model\n",
    "        class_output = self.classifier(embedding)  # Output for classification\n",
    "        return embedding, class_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = '../../data/BiteCount/salient_poses/'\n",
    "\n",
    "# Define transformations for training set and validation set\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resizing to square input\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resizing to square input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = TripletDataset(data_dir, transform=train_transforms)\n",
    "dataset_size = len(dataset)\n",
    "class_names = dataset.classes\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "class_names = dataset.classes\n",
    "\n",
    "# # Cross-validation setup\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Split the dataset randomly into training and validation sets\n",
    "train_size = int(0.8 * dataset_size)  # 80% training, 20% validation\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 25\n",
    "patience = 5\n",
    "alpha = 0.5\n",
    "\n",
    "# Placeholder to store metrics across folds\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "roc_aucs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Unpack the batch\n",
    "    anchors, positives, negatives, labels = zip(*batch)\n",
    "\n",
    "    # Stack tensors to create batches\n",
    "    anchors = torch.stack(anchors)\n",
    "    positives = torch.stack(positives)\n",
    "    negatives = torch.stack(negatives)\n",
    "\n",
    "    # Convert labels to a tensor\n",
    "    labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    return anchors, positives, negatives, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "# Perform 5-Fold Cross Validation\n",
    "fold_idx = 1\n",
    "num_epochs = 25\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tuning: Experiment with different values for learning rate and momentum\n",
    "# alphas = [i*0.1 for i in range(1, 11)]\n",
    "\n",
    "# best_val_acc = 0.0\n",
    "# best_lr = None\n",
    "# best_momentum = None\n",
    "# best_val_loss = 1e10\n",
    "\n",
    "# for alpha in alphas:\n",
    "#     print(f\"Training with alpha: {alpha}\")\n",
    "#     # Initialize TripletModel\n",
    "#     triplet_model = TripletModel()\n",
    "#     model = TripletClassifier(triplet_model)\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     # Define loss functions and optimizer\n",
    "#     criterion_classification = nn.BCEWithLogitsLoss()  # Binary cross-entropy with logits for binary classification\n",
    "#     criterion_triplet = nn.TripletMarginLoss()  # Triplet margin loss\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "#     patience_counter = 0\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "\n",
    "#         for batch in train_loader:\n",
    "#             # Unpack the batch correctly\n",
    "#             anchor, positive, negative, labels = batch\n",
    "            \n",
    "#             # Move the tensors to the appropriate device\n",
    "#             anchor = anchor.to(device)\n",
    "#             positive = positive.to(device)\n",
    "#             negative = negative.to(device)\n",
    "#             labels = labels.to(device)  # Ensure labels are tensors\n",
    "\n",
    "#             # Forward pass\n",
    "#             anchor_embedding, anchor_output = model(anchor)\n",
    "#             positive_embedding, positive_output = model(positive)\n",
    "#             negative_embedding, negative_output = model(negative)\n",
    "\n",
    "#             # Calculate losses\n",
    "#             classification_loss = criterion_classification(anchor_output, labels)\n",
    "#             triplet_loss = criterion_triplet(anchor_embedding, positive_embedding, negative_embedding)\n",
    "\n",
    "#             # Combine losses\n",
    "#             loss = alpha * classification_loss + (1-alpha) * triplet_loss\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         avg_loss = running_loss / len(train_loader)\n",
    "#         print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "#         # Validation step\n",
    "#         model.eval()\n",
    "#         val_preds, val_labels = [], []\n",
    "#         val_loss = 0.0\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_loader:\n",
    "#                 anchor, positive, negative, labels = batch\n",
    "                \n",
    "#                 anchor = anchor.to(device)\n",
    "#                 positive = positive.to(device)\n",
    "#                 negative = negative.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 anchor_embedding, anchor_output = model(anchor)\n",
    "#                 positive_embedding, positive_output = model(positive)\n",
    "#                 negative_embedding, negative_output = model(negative)\n",
    "\n",
    "#                 # Compute validation loss\n",
    "#                 classification_loss = criterion_classification(anchor_output, labels)\n",
    "#                 triplet_loss = criterion_triplet(anchor_embedding, positive_embedding, negative_embedding)\n",
    "#                 val_loss += (classification_loss + triplet_loss).item()\n",
    "\n",
    "#                 val_preds.append(torch.sigmoid(anchor_output).cpu().numpy())\n",
    "#                 val_labels.append(labels.cpu().numpy())\n",
    "\n",
    "#         avg_val_loss = val_loss / len(val_loader)\n",
    "#         val_preds = np.concatenate(val_preds)\n",
    "#         val_labels = np.concatenate(val_labels)\n",
    "\n",
    "#         # Calculate metrics\n",
    "#         val_acc = accuracy_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "#         val_f1 = f1_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "#         precision = precision_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "#         recall = recall_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "#         roc_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "#         # Print validation metrics\n",
    "#         print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}, \"\n",
    "#               f\"Precision: {precision:.4f}, Recall: {recall:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "#         # Early stopping logic\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "#             best_alpha = alpha\n",
    "#             patience_counter = 0\n",
    "#             # Save model state\n",
    "#             torch.save(model.state_dict(), f'triplet_classifier_fold_{fold_idx}.pth')\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(\"Early stopping triggered.\")\n",
    "#                 break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Best alpha: {best_alpha}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with margin: 0.1, alpha: 0.1, learning_rate: 0.001, momentum: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 1.4759\n",
      "Validation Loss: 2.1951, Accuracy: 0.4750, F1 Score: 0.4474, Precision: 0.4722, Recall: 0.4250, ROC AUC: 0.4806\n",
      "Epoch [2/25], Loss: 1.2775\n",
      "Validation Loss: 2.0142, Accuracy: 0.5375, F1 Score: 0.4789, Precision: 0.5484, Recall: 0.4250, ROC AUC: 0.5062\n",
      "Epoch [3/25], Loss: 1.1008\n",
      "Validation Loss: 1.7801, Accuracy: 0.5250, F1 Score: 0.5250, Precision: 0.5250, Recall: 0.5250, ROC AUC: 0.4875\n",
      "Epoch [4/25], Loss: 0.9404\n",
      "Validation Loss: 1.7411, Accuracy: 0.4750, F1 Score: 0.4615, Precision: 0.4737, Recall: 0.4500, ROC AUC: 0.4875\n",
      "Epoch [5/25], Loss: 0.9179\n",
      "Validation Loss: 1.5866, Accuracy: 0.4875, F1 Score: 0.4533, Precision: 0.4857, Recall: 0.4250, ROC AUC: 0.5119\n",
      "Epoch [6/25], Loss: 0.8086\n",
      "Validation Loss: 1.5542, Accuracy: 0.5000, F1 Score: 0.5122, Precision: 0.5000, Recall: 0.5250, ROC AUC: 0.4931\n",
      "Epoch [7/25], Loss: 0.7983\n",
      "Validation Loss: 1.5738, Accuracy: 0.4625, F1 Score: 0.4267, Precision: 0.4571, Recall: 0.4000, ROC AUC: 0.4594\n",
      "Epoch [8/25], Loss: 0.7257\n",
      "Validation Loss: 1.4669, Accuracy: 0.5125, F1 Score: 0.5185, Precision: 0.5122, Recall: 0.5250, ROC AUC: 0.5169\n",
      "Epoch [9/25], Loss: 0.7095\n",
      "Validation Loss: 1.3792, Accuracy: 0.4875, F1 Score: 0.5176, Precision: 0.4889, Recall: 0.5500, ROC AUC: 0.4856\n",
      "Epoch [10/25], Loss: 0.6927\n",
      "Validation Loss: 1.3482, Accuracy: 0.4500, F1 Score: 0.5000, Precision: 0.4583, Recall: 0.5500, ROC AUC: 0.4437\n",
      "Epoch [11/25], Loss: 0.6460\n",
      "Validation Loss: 1.4321, Accuracy: 0.5125, F1 Score: 0.5618, Precision: 0.5102, Recall: 0.6250, ROC AUC: 0.5162\n",
      "Epoch [12/25], Loss: 0.6381\n",
      "Validation Loss: 1.3675, Accuracy: 0.4250, F1 Score: 0.4773, Precision: 0.4375, Recall: 0.5250, ROC AUC: 0.4237\n",
      "Epoch [13/25], Loss: 0.6111\n",
      "Validation Loss: 1.3127, Accuracy: 0.4000, F1 Score: 0.4545, Precision: 0.4167, Recall: 0.5000, ROC AUC: 0.4075\n",
      "Epoch [14/25], Loss: 0.5665\n",
      "Validation Loss: 1.2397, Accuracy: 0.4500, F1 Score: 0.5000, Precision: 0.4583, Recall: 0.5500, ROC AUC: 0.4075\n",
      "Epoch [15/25], Loss: 0.5585\n",
      "Validation Loss: 1.3221, Accuracy: 0.5000, F1 Score: 0.5455, Precision: 0.5000, Recall: 0.6000, ROC AUC: 0.4963\n",
      "Epoch [16/25], Loss: 0.5623\n",
      "Validation Loss: 1.3304, Accuracy: 0.5125, F1 Score: 0.5618, Precision: 0.5102, Recall: 0.6250, ROC AUC: 0.4781\n",
      "Epoch [17/25], Loss: 0.5392\n",
      "Validation Loss: 1.2565, Accuracy: 0.4250, F1 Score: 0.4889, Precision: 0.4400, Recall: 0.5500, ROC AUC: 0.3938\n",
      "Epoch [18/25], Loss: 0.5025\n",
      "Validation Loss: 1.2129, Accuracy: 0.4625, F1 Score: 0.5275, Precision: 0.4706, Recall: 0.6000, ROC AUC: 0.4419\n",
      "Epoch [19/25], Loss: 0.5072\n",
      "Validation Loss: 1.2282, Accuracy: 0.5500, F1 Score: 0.6087, Precision: 0.5385, Recall: 0.7000, ROC AUC: 0.5681\n",
      "Epoch [20/25], Loss: 0.5127\n",
      "Validation Loss: 1.2472, Accuracy: 0.4625, F1 Score: 0.5057, Precision: 0.4681, Recall: 0.5500, ROC AUC: 0.4856\n",
      "Epoch [21/25], Loss: 0.5120\n",
      "Validation Loss: 1.2289, Accuracy: 0.5375, F1 Score: 0.5747, Precision: 0.5319, Recall: 0.6250, ROC AUC: 0.4631\n",
      "Epoch [22/25], Loss: 0.4482\n",
      "Validation Loss: 1.2553, Accuracy: 0.5125, F1 Score: 0.5806, Precision: 0.5094, Recall: 0.6750, ROC AUC: 0.4563\n",
      "Epoch [23/25], Loss: 0.4746\n",
      "Validation Loss: 1.2600, Accuracy: 0.4750, F1 Score: 0.5116, Precision: 0.4783, Recall: 0.5500, ROC AUC: 0.4237\n",
      "Early stopping triggered.\n",
      "Training with margin: 0.1, alpha: 0.1, learning_rate: 0.001, momentum: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 1.4703\n",
      "Validation Loss: 2.2280, Accuracy: 0.3750, F1 Score: 0.3243, Precision: 0.3529, Recall: 0.3000, ROC AUC: 0.3569\n",
      "Epoch [2/25], Loss: 1.1818\n",
      "Validation Loss: 1.8577, Accuracy: 0.4000, F1 Score: 0.2500, Precision: 0.3333, Recall: 0.2000, ROC AUC: 0.4038\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     39\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     42\u001b[0m     anchor, positive, negative, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     43\u001b[0m     anchor, positive, negative, labels \u001b[38;5;241m=\u001b[39m anchor\u001b[38;5;241m.\u001b[39mto(device), positive\u001b[38;5;241m.\u001b[39mto(device), negative\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Desktop/cow-bytes/experiments/4_loss_function/triplet_utils.py:50\u001b[0m, in \u001b[0;36mTripletDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     47\u001b[0m negative_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_negative_frame_path(other_class, video_name)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Load images\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m anchor_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m positive_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_image(positive_path)\n\u001b[1;32m     52\u001b[0m negative_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_image(negative_path)\n",
      "File \u001b[0;32m~/Desktop/cow-bytes/experiments/4_loss_function/triplet_utils.py:85\u001b[0m, in \u001b[0;36mTripletDataset.load_image\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m---> 85\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ensure image is in RGB format\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     87\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/PIL/Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cowbytes/lib/python3.8/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Define the range of hyperparameters to test\n",
    "margins = [i * 0.1 for i in range(1, 11)]  # Margin from 0.1 to 1.0\n",
    "alphas = [0.1, 0.3, 0.5, 0.7, 0.9]  # Different values for alpha\n",
    "learning_rates = [0.001, 0.01, 0.1]  # Example learning rates\n",
    "momentums = [0.5, 0.8, 0.9]  # Different momentum values\n",
    "\n",
    "# Store the best results\n",
    "best_val_acc = 0.0\n",
    "best_hyperparams = {}\n",
    "best_val_loss = 1e10\n",
    "\n",
    "# Create a search space using itertools\n",
    "search_space = itertools.product(margins, alphas, learning_rates, momentums)\n",
    "\n",
    "for margin, alpha, lr, momentum in search_space:\n",
    "    print(f\"Training with margin: {margin}, alpha: {alpha}, learning_rate: {lr}, momentum: {momentum}\")\n",
    "\n",
    "    # Initialize TripletModel\n",
    "    triplet_model = TripletModel()\n",
    "    model = TripletClassifier(triplet_model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss functions and optimizer\n",
    "    criterion_classification = nn.BCEWithLogitsLoss()  # Binary cross-entropy for classification\n",
    "    criterion_triplet = nn.TripletMarginLoss(margin=margin)  # Use margin from the search space\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)  # Optimizer with dynamic lr and momentum\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            anchor, positive, negative, labels = batch\n",
    "            anchor, positive, negative, labels = anchor.to(device), positive.to(device), negative.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            anchor_embedding, anchor_output = model(anchor)\n",
    "            positive_embedding, positive_output = model(positive)\n",
    "            negative_embedding, negative_output = model(negative)\n",
    "\n",
    "            # Calculate losses\n",
    "            classification_loss = criterion_classification(anchor_output, labels)\n",
    "            triplet_loss = criterion_triplet(anchor_embedding, positive_embedding, negative_embedding)\n",
    "\n",
    "            # Combine losses\n",
    "            loss = alpha * classification_loss + (1 - alpha) * triplet_loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                anchor, positive, negative, labels = batch\n",
    "                anchor, positive, negative, labels = anchor.to(device), positive.to(device), negative.to(device), labels.to(device)\n",
    "\n",
    "                anchor_embedding, anchor_output = model(anchor)\n",
    "                positive_embedding, positive_output = model(positive)\n",
    "                negative_embedding, negative_output = model(negative)\n",
    "\n",
    "                # Compute validation loss\n",
    "                classification_loss = criterion_classification(anchor_output, labels)\n",
    "                triplet_loss = criterion_triplet(anchor_embedding, positive_embedding, negative_embedding)\n",
    "                val_loss += (classification_loss + triplet_loss).item()\n",
    "\n",
    "                val_preds.append(torch.sigmoid(anchor_output).cpu().numpy())\n",
    "                val_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_preds = np.concatenate(val_preds)\n",
    "        val_labels = np.concatenate(val_labels)\n",
    "\n",
    "        # Calculate validation metrics\n",
    "        val_acc = accuracy_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "        val_f1 = f1_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "        precision = precision_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "        recall = recall_score(val_labels, (val_preds > 0.5).astype(int))\n",
    "        roc_auc = roc_auc_score(val_labels, val_preds)\n",
    "\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}, \"\n",
    "              f\"Precision: {precision:.4f}, Recall: {recall:.4f}, ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Early stopping and best model saving\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_val_acc = val_acc\n",
    "            best_hyperparams = {'margin': margin, 'alpha': alpha, 'learning_rate': lr, 'momentum': momentum}\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f'triplet_classifier_best_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "# Save the results to a text file\n",
    "with open('best_hyperparameters_tmm.txt', 'w') as f:\n",
    "    f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "    f.write(f\"Best accuracy: {best_val_acc:.4f}\\n\")\n",
    "    f.write(f\"Best hyperparameters:\\n\")\n",
    "    f.write(f\"  Margin: {best_hyperparams['margin']}\\n\")\n",
    "    f.write(f\"  Alpha: {best_hyperparams['alpha']}\\n\")\n",
    "    f.write(f\"  Learning Rate: {best_hyperparams['learning_rate']}\\n\")\n",
    "    f.write(f\"  Momentum: {best_hyperparams['momentum']}\\n\")\n",
    "\n",
    "print(\"Results saved to 'best_hyperparameters_results.txt'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplabcut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
