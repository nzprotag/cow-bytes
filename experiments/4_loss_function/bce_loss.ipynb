{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    return torch.stack(images), torch.tensor(labels)[:, None]  # Reshape labels to (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your dataset directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/BiteCount/salient_poses/' \n",
    "\n",
    "# Define transformations for training set and validation set\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 244)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 244)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the dataset with training transformations\n",
    "dataset = datasets.ImageFolder(data_dir, transform=train_transforms)\n",
    "dataset_size = len(dataset)\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create data loaders for train and validation datasets\n",
    "batch_size = 192\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "num_epochs = 25\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/sadat/miniconda3/envs/cowbytes/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] - Train Loss: 0.7034, Train Acc: 95.2609, Val Loss: 0.6951, Val Acc: 0.5053, Val F1: 0.3094, Val Precision: 0.4634, Val Recall: 0.2323, Val ROC-AUC: 0.5208\n",
      "Validation accuracy improved to 0.5053. Saving model.\n",
      "Epoch [2/25] - Train Loss: 0.6902, Train Acc: 95.2259, Val Loss: 0.6914, Val Acc: 0.5088, Val F1: 0.6134, Val Precision: 0.4912, Val Recall: 0.8166, Val ROC-AUC: 0.5074\n",
      "Validation accuracy improved to 0.5088. Saving model.\n",
      "Epoch [3/25] - Train Loss: 0.6855, Train Acc: 95.2347, Val Loss: 0.6944, Val Acc: 0.5041, Val F1: 0.5176, Val Precision: 0.4831, Val Recall: 0.5575, Val ROC-AUC: 0.5075\n",
      "Epoch [4/25] - Train Loss: 0.6795, Train Acc: 95.2609, Val Loss: 0.6962, Val Acc: 0.5321, Val F1: 0.3802, Val Precision: 0.5168, Val Recall: 0.3007, Val ROC-AUC: 0.5290\n",
      "Validation accuracy improved to 0.5321. Saving model.\n",
      "Epoch [5/25] - Train Loss: 0.6760, Train Acc: 95.2522, Val Loss: 0.6994, Val Acc: 0.5403, Val F1: 0.2423, Val Precision: 0.5676, Val Recall: 0.1540, Val ROC-AUC: 0.5558\n",
      "Validation accuracy improved to 0.5403. Saving model.\n",
      "Epoch [6/25] - Train Loss: 0.6664, Train Acc: 95.2434, Val Loss: 0.6928, Val Acc: 0.5706, Val F1: 0.3566, Val Precision: 0.6258, Val Recall: 0.2494, Val ROC-AUC: 0.5861\n",
      "Validation accuracy improved to 0.5706. Saving model.\n",
      "Epoch [7/25] - Train Loss: 0.6536, Train Acc: 95.2872, Val Loss: 0.6747, Val Acc: 0.5694, Val F1: 0.6103, Val Precision: 0.5372, Val Recall: 0.7066, Val ROC-AUC: 0.6064\n",
      "Validation accuracy improved to 0.5694. Saving model.\n",
      "Epoch [8/25] - Train Loss: 0.6365, Train Acc: 95.2259, Val Loss: 0.6635, Val Acc: 0.6208, Val F1: 0.5707, Val Precision: 0.6207, Val Recall: 0.5281, Val ROC-AUC: 0.6585\n",
      "Validation accuracy improved to 0.6208. Saving model.\n",
      "Epoch [9/25] - Train Loss: 0.6080, Train Acc: 95.2259, Val Loss: 0.6279, Val Acc: 0.6499, Val F1: 0.6333, Val Precision: 0.6333, Val Recall: 0.6333, Val ROC-AUC: 0.7261\n",
      "Validation accuracy improved to 0.6499. Saving model.\n",
      "Epoch [10/25] - Train Loss: 0.5630, Train Acc: 95.2609, Val Loss: 0.5802, Val Acc: 0.7036, Val F1: 0.6833, Val Precision: 0.6972, Val Recall: 0.6699, Val ROC-AUC: 0.7863\n",
      "Validation accuracy improved to 0.7036. Saving model.\n",
      "Epoch [11/25] - Train Loss: 0.4872, Train Acc: 95.1996, Val Loss: 0.4982, Val Acc: 0.7468, Val F1: 0.7257, Val Precision: 0.7513, Val Recall: 0.7017, Val ROC-AUC: 0.8533\n",
      "Validation accuracy improved to 0.7468. Saving model.\n",
      "Epoch [12/25] - Train Loss: 0.4055, Train Acc: 95.2609, Val Loss: 0.4533, Val Acc: 0.7666, Val F1: 0.7290, Val Precision: 0.8176, Val Recall: 0.6577, Val ROC-AUC: 0.8728\n",
      "Validation accuracy improved to 0.7666. Saving model.\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-Fold Cross Validation\n",
    "fold_idx = 1\n",
    "best_val_acc = 0.0\n",
    "val_accuracies = []\n",
    "val_f1_scores = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "roc_aucs = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(dataset):\n",
    "    print(f\"Fold {fold_idx}\")\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 1)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    # Training loop with early stopping mechanism\n",
    "    val_acc, val_f1, precision, recall, roc_auc, val_losses, val_f1_scores = train_and_evaluate(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device, 'bce_loss')\n",
    "    \n",
    "    # Store val_acc and val_f1 for current fold\n",
    "    val_accuracies.append(val_acc)\n",
    "    val_f1_scores.append(val_f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    # Check if current validation accuracy is the best so far\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "    \n",
    "    fold_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best Validation Accuracy: {best_val_acc}\")\n",
    "print(f\"Validation Accuracies for all folds: {val_accuracies}\")\n",
    "print(f\"Validation F1 Scores for all folds: {val_f1_scores}\")\n",
    "print(f\"Precision for all folds: {precisions}\")\n",
    "print(f\"Recall for all folds: {recalls}\")\n",
    "print(f\"ROC AUC for all folds: {roc_aucs}\")\n",
    "\n",
    "# Calculate mean and standard deviation of validation accuracies\n",
    "mean_val_acc = np.mean(val_accuracies)\n",
    "std_val_acc = np.std(val_accuracies)\n",
    "\n",
    "print(f\"Mean Validation Accuracy: {mean_val_acc:.4f} +/- {std_val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplabcut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
